{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE-GAN Training Notebook (Standalone)\n",
    "\n",
    "This notebook trains a Generative Adversarial Network (GAN) using a pre-trained VAE's decoder as the generator. It is completely self-contained and can be run on platforms like Google Colab without any external file dependencies.\n",
    "\n",
    "### Steps:\n",
    "1. **Setup**: Installs necessary libraries and defines all required classes and configuration parameters.\n",
    "2. **Initialization**: Sets up the dataset, models (Generator and Discriminator), optimizers, and loss function.\n",
    "3. **Training**: Runs the main training loop.\n",
    "4. **Logging & Saving**: Logs results to Weights & Biases and saves model checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install torch torchvision tqdm wandb numpy matplotlib imageio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from tqdm.notebook import tqdm\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All-in-One Code Block: Config, Models, and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required classes and functions are defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration Class ---\n",
    "class Config():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    seed = 42\n",
    "    dataset_name = \"CIFAR-10\"\n",
    "    image_size = 32\n",
    "    in_channels = 3\n",
    "    out_channels = 3\n",
    "    encoder_channels = [32, 64, 128]\n",
    "    decoder_channels = [128, 64, 32]\n",
    "    kernel_size = 4\n",
    "    latent_dim = 128\n",
    "    hidden_dim = 512\n",
    "    batch_size = 128\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 50\n",
    "    d_features = 64\n",
    "    gan_lr = 2e-4\n",
    "    gan_epochs = 50\n",
    "    checkpoint_interval = 10\n",
    "    sample_interval = 5\n",
    "    log_interval = 100\n",
    "    save_reconstruction_interval = 2\n",
    "    data_path = \"./data\"\n",
    "    reconstruction_save_path = \"./saves/reconstructions\"\n",
    "    model_save_path = \"./saves/checkpoints\"\n",
    "    dataset_path = \"./data\"\n",
    "    sample_dir = \"./saves/gan_samples\"\n",
    "    wandb_project = \"VAE-GAN-CIFAR-10-Colab\"\n",
    "    wandb_run_name = \"gan_run\"\n",
    "\n",
    "# --- VAE Model --- \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=Config.in_channels, out_channels=Config.encoder_channels[0], kernel_size=Config.kernel_size, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(Config.encoder_channels[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=Config.encoder_channels[0], out_channels=Config.encoder_channels[1], kernel_size=Config.kernel_size, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(Config.encoder_channels[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=Config.encoder_channels[1], out_channels=Config.encoder_channels[2], kernel_size=Config.kernel_size, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(Config.encoder_channels[2]),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mu = nn.Linear(in_features=Config.encoder_channels[2] * 4 * 4, out_features=Config.latent_dim)\n",
    "        self.logvar = nn.Linear(in_features=Config.encoder_channels[2] * 4 * 4, out_features=Config.latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.flatten(x)\n",
    "        mu = self.mu(x)\n",
    "        logvar = self.logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_features=Config.latent_dim, out_features=Config.decoder_channels[0]*4*4)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=Config.decoder_channels[0], out_channels=Config.decoder_channels[1], kernel_size=Config.kernel_size, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(Config.decoder_channels[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=Config.decoder_channels[1], out_channels=Config.decoder_channels[2], kernel_size=Config.kernel_size, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(Config.decoder_channels[2]),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=Config.decoder_channels[2], out_channels=Config.out_channels, kernel_size=Config.kernel_size, stride=2, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        x = x.view(-1, Config.decoder_channels[0], 4, 4)\n",
    "        x = self.deconv(x)\n",
    "        return x\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed, mu, logvar\n",
    "\n",
    "# --- Discriminator Model ---\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=Config.in_channels, base_channels=Config.d_features):\n",
    "        super().__init__()\n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=base_channels, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=base_channels, out_channels=base_channels*2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_channels * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=base_channels*2, out_channels=base_channels*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(base_channels*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(in_channels=base_channels*4, out_channels=1, kernel_size=4, stride=1, bias=False),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.discriminator(x)\n",
    "        return out.view(-1)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "def create_interpolation_gif(decoder, latent_dim, steps, gif_save_path):\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        z_start = torch.randn(1, latent_dim).to(next(decoder.parameters()).device)\n",
    "        z_end = torch.randn(1, latent_dim).to(next(decoder.parameters()).device)\n",
    "        ratios = torch.linspace(0, 1, steps).unsqueeze(1).to(z_start.device)\n",
    "        z_interpolate = z_start * (1 - ratios) + z_end * ratios\n",
    "        imgs = decoder(z_interpolate).cpu()\n",
    "        imgs = (imgs + 1) / 2\n",
    "        grid_imgs = [make_grid(img.unsqueeze(0), nrow=1).permute(1, 2, 0).numpy() for img in imgs]\n",
    "        grid_imgs = [(img * 255).astype(np.uint8) for img in grid_imgs]\n",
    "        imageio.mimsave(gif_save_path, grid_imgs, fps=5)\n",
    "    decoder.train()\n",
    "\n",
    "print(\"All required classes and functions are defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Discriminator_Loss</td><td>▁</td></tr><tr><td>Epoch</td><td>▁</td></tr><tr><td>Generator_Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Discriminator_Loss</td><td>0.21534</td></tr><tr><td>Epoch</td><td>1</td></tr><tr><td>Generator_Loss</td><td>3.29011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gan_colab_run</strong> at: <a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab/runs/z0os4sdk' target=\"_blank\">https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab/runs/z0os4sdk</a><br> View project at: <a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab' target=\"_blank\">https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250721_163553-z0os4sdk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Atharva\\Projects\\Image_Generation_VAE+GAN\\wandb\\run-20250721_165840-w3wghhmj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab/runs/w3wghhmj' target=\"_blank\">gan_colab_run_2</a></strong> to <a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab' target=\"_blank\">https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab/runs/w3wghhmj' target=\"_blank\">https://wandb.ai/atharv3105-dr-a-p-j-abdul-kalam-technical-university/VAE-GAN-CIFAR-10-Colab/runs/w3wghhmj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB initialized and directories created.\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(Config.seed)\n",
    "\n",
    "# --- Initialize WandB ---\n",
    "# You will be prompted to login to wandb\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "    project=Config.wandb_project,\n",
    "    name=Config.wandb_run_name + \"_2\",\n",
    "    config={k:v for k,v in Config.__dict__.items() if not k.startswith(\"__\")}\n",
    ")\n",
    "\n",
    "# --- Create necessary directories ---\n",
    "os.makedirs(Config.sample_dir, exist_ok=True)\n",
    "os.makedirs(Config.model_save_path, exist_ok=True)\n",
    "\n",
    "print(\"WandB initialized and directories created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Found 50000 images.\n"
     ]
    }
   ],
   "source": [
    "# --- Load The Dataset ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((Config.image_size, Config.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root=Config.data_path, train=True, transform=transform, download=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Dataset loaded. Found {len(train_dataset)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Note on the Pre-trained VAE Model\n",
    "This notebook requires a pre-trained VAE model to use its decoder as the generator. Since we cannot directly load a local file in this standalone notebook, we will first train a VAE from scratch in the next cell. If you have a pre-trained `vae_epoch_50.pt` file, you can upload it to your Colab environment and modify the path in the subsequent cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2a: Train the VAE (or load if you have it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VAE Training Cell ---\n",
    "print(\"Starting VAE training...\")\n",
    "vae = VAE().to(Config.device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=Config.learning_rate)\n",
    "loss_fn = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "for epoch in range(Config.num_epochs):\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"VAE Epoch [{epoch+1}/{Config.num_epochs}]\", leave=False)\n",
    "    for i, (images, _) in loop:\n",
    "        images = images.to(Config.device)\n",
    "        recon_images, mu, logvar = vae(images)\n",
    "        \n",
    "        recon_loss = loss_fn(recon_images, images)\n",
    "        kld = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        loss = recon_loss + kld\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Save the trained VAE model\n",
    "vae_model_path = os.path.join(Config.model_save_path, \"vae_epoch_50.pt\")\n",
    "torch.save(vae.state_dict(), vae_model_path)\n",
    "print(f\"VAE training complete. Model saved to {vae_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./saves/checkpoints'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Config.model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Temp\\ipykernel_6804\\4121309907.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(vae_model_path, map_location=Config.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained VAE model loaded successfully from ./saves/checkpoints\\vae_epoch_50.pt\n",
      "GAN components initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize GAN Models, Optimizers, and Loss Function ---\n",
    "\n",
    "# Load the just-trained VAE to use its decoder as the generator\n",
    "vae_model_path = os.path.join(Config.model_save_path, \"vae_epoch_50.pt\")\n",
    "checkpoint = torch.load(vae_model_path, map_location=Config.device)\n",
    "vae = VAE().to(Config.device)\n",
    "vae.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Pre-trained VAE model loaded successfully from {vae_model_path}\")\n",
    "    \n",
    "decoder = vae.decoder.to(Config.device) # This is our Generator\n",
    "\n",
    "# Initialize the Discriminator\n",
    "discriminator = Discriminator().to(Config.device)\n",
    "\n",
    "# Optimizers & Loss Function\n",
    "gen_optimizer = optim.Adam(decoder.parameters(), lr=Config.gan_lr, betas=(0.5, 0.999))\n",
    "disc_optimizer = optim.Adam(discriminator.parameters(), lr=Config.gan_lr, betas=(0.5, 0.999))\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"GAN components initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GAN training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f0021133b840a6976884b284f7fe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [1/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Completed | Avg D_Loss: 0.1606 | Avg G_Loss: 3.4944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7566389c566d4ff2a22990d4c6d031bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [2/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Completed | Avg D_Loss: 0.1662 | Avg G_Loss: 3.1941\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768bb56cca67425ba5a0c14d12cddf3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [3/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Completed | Avg D_Loss: 0.1596 | Avg G_Loss: 3.1417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf822dbbf13e4101af403616712966fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [4/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Completed | Avg D_Loss: 0.1589 | Avg G_Loss: 3.0231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "726d92fddf544e668f3485af512764a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [5/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Completed | Avg D_Loss: 0.1743 | Avg G_Loss: 2.9335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73a0e04574d4bb18f5e4d9b26b5b958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [6/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Completed | Avg D_Loss: 0.1807 | Avg G_Loss: 2.9742\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cfd4be0eba44ea81ee6e6680161f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [7/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Completed | Avg D_Loss: 0.1739 | Avg G_Loss: 3.1046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b97467616f4fdea34130cc417d64b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [8/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Completed | Avg D_Loss: 0.1515 | Avg G_Loss: 3.1530\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481da0c96d914441870b5c026aed9141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [9/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Completed | Avg D_Loss: 0.1636 | Avg G_Loss: 3.1696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b56180d3438418ebdedbb4c592abe46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [10/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Completed | Avg D_Loss: 0.1474 | Avg G_Loss: 3.2291\n",
      "Checkpoint saved to ./saves/checkpoints\\gan_checkpoint_epoch_10.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066a4e1b48c24132b5af008412bd9f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [11/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Completed | Avg D_Loss: 0.1633 | Avg G_Loss: 3.2630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0125556d8d514a788fed7edb836f8c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [12/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Completed | Avg D_Loss: 0.1189 | Avg G_Loss: 3.3371\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acb43130b524480992bb49249a4265a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [13/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Completed | Avg D_Loss: 0.1952 | Avg G_Loss: 3.2487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb962db7d463431aac2bf95bbab7a687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [14/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Completed | Avg D_Loss: 0.1515 | Avg G_Loss: 3.2716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddb5a286039446ba30a24704f464e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [15/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Completed | Avg D_Loss: 0.1263 | Avg G_Loss: 3.3857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b5ccee27804d1daee0563ca1bfb135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [16/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Completed | Avg D_Loss: 0.1514 | Avg G_Loss: 3.4394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d1deda16c943cca7ede01846c68fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [17/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Completed | Avg D_Loss: 0.1408 | Avg G_Loss: 3.4097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603e0037e29741808fc2ddb32dfe8635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [18/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Completed | Avg D_Loss: 0.1359 | Avg G_Loss: 3.5170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd380f175c942a6bae1241cc75a3cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [19/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Completed | Avg D_Loss: 0.1003 | Avg G_Loss: 3.6285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b16330d00b4ff89715b875f150ffdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [20/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Completed | Avg D_Loss: 0.1494 | Avg G_Loss: 3.6396\n",
      "Checkpoint saved to ./saves/checkpoints\\gan_checkpoint_epoch_20.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32714bec7c02462e94891f3c1d00335b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [21/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Completed | Avg D_Loss: 0.0510 | Avg G_Loss: 3.8050\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e7d71c66e84ae897b9d2f466afd10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [22/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Completed | Avg D_Loss: 0.1349 | Avg G_Loss: 3.7006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271ad747961049e8973e075d11e6df91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [23/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Completed | Avg D_Loss: 0.1278 | Avg G_Loss: 3.7332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c47a4d674db44e08bb5f0be57131e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [24/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Completed | Avg D_Loss: 0.0876 | Avg G_Loss: 3.9249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59759f7fd7ee4fbab6287074c5fae346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [25/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Completed | Avg D_Loss: 0.1449 | Avg G_Loss: 3.8110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b57ffc8d4c441eeaa392073c2e306ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [26/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Completed | Avg D_Loss: 0.0982 | Avg G_Loss: 3.8978\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ab4e53471f427da0dc3766457b01c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [27/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Completed | Avg D_Loss: 0.1324 | Avg G_Loss: 3.7806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dfe01a218349519c281528452bd2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [28/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Completed | Avg D_Loss: 0.1501 | Avg G_Loss: 3.8620\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813be810bbb247aab83983935361cf53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [29/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Completed | Avg D_Loss: 0.0450 | Avg G_Loss: 4.1399\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "915ec968dc4c45fb8b84e5871608448d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [30/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Completed | Avg D_Loss: 0.1074 | Avg G_Loss: 4.0649\n",
      "Checkpoint saved to ./saves/checkpoints\\gan_checkpoint_epoch_30.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3134866bc108424e80c09e69dc6d18f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [31/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Completed | Avg D_Loss: 0.1128 | Avg G_Loss: 4.0354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f05df135824d0fa4505967e1abdb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [32/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Completed | Avg D_Loss: 0.0902 | Avg G_Loss: 4.2210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52f2c9b95bb46a29cae1e2dcfb07432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [33/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Completed | Avg D_Loss: 0.1542 | Avg G_Loss: 3.9426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8333b3aca8cd445c973614258297b0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [34/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Completed | Avg D_Loss: 0.0386 | Avg G_Loss: 4.2717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cb839e7b7345f18790939f782b9dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [35/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Completed | Avg D_Loss: 0.1544 | Avg G_Loss: 3.9673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0238a0bd57f54ab7b3917dbda38e2a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [36/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Completed | Avg D_Loss: 0.0331 | Avg G_Loss: 4.3971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f85d63b27d4773b85c67c17be230ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [37/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Completed | Avg D_Loss: 0.1946 | Avg G_Loss: 3.7709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33edec635ac64980aa669db7e75d4231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [38/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Completed | Avg D_Loss: 0.0332 | Avg G_Loss: 4.3347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d227f5526874460a993ede1e0fd04310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [39/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Completed | Avg D_Loss: 0.1738 | Avg G_Loss: 4.0346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28322babaa4d409e9e7126540adcea38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [40/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Completed | Avg D_Loss: 0.1184 | Avg G_Loss: 4.0731\n",
      "Checkpoint saved to ./saves/checkpoints\\gan_checkpoint_epoch_40.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534d707c9f8c4c439a0921faa100b7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [41/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Completed | Avg D_Loss: 0.0510 | Avg G_Loss: 4.1837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9012280b1ca647899e69d01c0e2b7ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [42/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Completed | Avg D_Loss: 0.1529 | Avg G_Loss: 3.9959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c119f0d0a2b400e9ae9054bb123271a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [43/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Completed | Avg D_Loss: 0.1424 | Avg G_Loss: 3.9723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9906845c7f4e448e877efcac06928480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [44/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Completed | Avg D_Loss: 0.0326 | Avg G_Loss: 4.3615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f72b7acdb44f3cbf1925a0cf938a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [45/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Completed | Avg D_Loss: 0.1022 | Avg G_Loss: 4.3502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff889e31462f450b92eb1ccfdbfae0ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [46/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Completed | Avg D_Loss: 0.0846 | Avg G_Loss: 4.3919\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8112c0577b4a5f9233f5d6a6e5ca32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [47/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Completed | Avg D_Loss: 0.1385 | Avg G_Loss: 3.9699\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc0b1ea316d4baeb97205e2f91cf832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [48/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Completed | Avg D_Loss: 0.0329 | Avg G_Loss: 4.4216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2548f29934e41cb9ccc71912b9ec116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [49/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Completed | Avg D_Loss: 0.0241 | Avg G_Loss: 4.8433\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a89aa236d65468ebe9f7632b7651aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GAN Epoch [50/50]:   0%|          | 0/391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50] Completed | Avg D_Loss: 0.2238 | Avg G_Loss: 3.8056\n",
      "Checkpoint saved to ./saves/checkpoints\\gan_checkpoint_epoch_50.pt\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "decoder.train()\n",
    "discriminator.train()\n",
    "\n",
    "print(\"Starting GAN training...\")\n",
    "\n",
    "for epoch in range(Config.gan_epochs):\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"GAN Epoch [{epoch + 1}/{Config.gan_epochs}]\", leave=False)\n",
    "    epoch_g_losses, epoch_d_losses = [], []\n",
    "    \n",
    "    for i, (real_imgs, _) in loop:\n",
    "        \n",
    "        real_imgs = real_imgs.to(Config.device)\n",
    "        batch_size = real_imgs.size(0)\n",
    "        \n",
    "        real_labels = torch.ones(batch_size, 1, device=Config.device).squeeze(1)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=Config.device).squeeze(1)\n",
    "        \n",
    "        # --- Train Discriminator ---\n",
    "        z = torch.randn(batch_size, Config.latent_dim).to(Config.device)\n",
    "        fake_imgs_detached = decoder(z).detach()\n",
    "        \n",
    "        real_preds = discriminator(real_imgs)\n",
    "        fake_preds = discriminator(fake_imgs_detached)\n",
    "        \n",
    "        d_loss_real = criterion(real_preds, real_labels)\n",
    "        d_loss_fake = criterion(fake_preds, fake_labels)\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "        \n",
    "        disc_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        # --- Train Generator ---\n",
    "        z = torch.randn(batch_size, Config.latent_dim).to(Config.device)\n",
    "        fake_imgs = decoder(z)\n",
    "        preds = discriminator(fake_imgs)\n",
    "        \n",
    "        g_loss = criterion(preds, real_labels)\n",
    "        \n",
    "        gen_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(D_Loss=d_loss.item(), G_Loss=g_loss.item())\n",
    "        epoch_d_losses.append(d_loss.item())\n",
    "        epoch_g_losses.append(g_loss.item())\n",
    "\n",
    "        #Log loss per step (batch)\n",
    "        global_step = epoch * len(train_loader) + i\n",
    "        wandb.log({\n",
    "            'Step_Discriminator_Loss': d_loss.item(),\n",
    "            'Step_Generator_Loss': g_loss.item(),\n",
    "            'Step': global_step\n",
    "        }, step=global_step)\n",
    "\n",
    "    # --- End of Epoch Logging & Saving ---\n",
    "    avg_d_loss = np.mean(epoch_d_losses)\n",
    "    avg_g_loss = np.mean(epoch_g_losses)\n",
    "\n",
    "    log_dict = {\n",
    "        'Epoch': epoch + 1,\n",
    "        'Discriminator_Loss': avg_d_loss,\n",
    "        'Generator_Loss': avg_g_loss,\n",
    "    }\n",
    "\n",
    "    if (epoch + 1) % Config.sample_interval == 0:\n",
    "        fake_grid = make_grid(fake_imgs[:16], nrow=4, normalize=True)\n",
    "        real_grid = make_grid(real_imgs[:16], nrow=4, normalize=True)\n",
    "        gif_save_path = os.path.join(Config.sample_dir, f\"interpolation_epoch_{epoch + 1}.gif\")\n",
    "        create_interpolation_gif(decoder, Config.latent_dim, steps=10, gif_save_path=gif_save_path)\n",
    "        \n",
    "        log_dict.update({\n",
    "            \"Sample_Image_Fake\": wandb.Image(fake_grid, caption=f\"Fake Samples at Epoch {epoch + 1}\"),\n",
    "            \"Sample_Image_Real\": wandb.Image(real_grid, caption=f\"Real Samples at Epoch {epoch + 1}\")\n",
    "        })\n",
    "        if os.path.exists(gif_save_path):\n",
    "            log_dict[\"Latent_Interpolation\"] = wandb.Video(gif_save_path, format=\"gif\")\n",
    "    \n",
    "    wandb.log(log_dict)\n",
    "    print(f\"Epoch [{epoch+1}/{Config.gan_epochs}] Completed | Avg D_Loss: {avg_d_loss:.4f} | Avg G_Loss: {avg_g_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % Config.checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(Config.model_save_path, f\"gan_checkpoint_epoch_{epoch+1}.pt\")\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"decoder_state_dict\": decoder.state_dict(),\n",
    "            \"discriminator_state_dict\": discriminator.state_dict(),\n",
    "            \"gen_optimizer_state_dict\": gen_optimizer.state_dict(),\n",
    "            \"disc_optimizer_state_dict\": disc_optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "           \n",
    "print(\"--- Training Finished ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Finalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the WandB run\n",
    "wandb.finish()\n",
    "print(\"WandB run finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
